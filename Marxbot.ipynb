{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "88e83b82-366d-41c9-82e4-d09d564ad70f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# MarxBot: Ask Marx Anything\n",
    "\n",
    "# Project Overview\n",
    "# A simple RAG (Retrieval-Augmented Generation) chatbot using TinyLlama,\n",
    "# backed by a vector database created from classic Marxist texts (public domain).\n",
    "\n",
    "# Requirements\n",
    "# pip install langchain chromadb sentence-transformers langchain-community"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d8f30b3d-ce2d-42fc-b02e-9903caa77077",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.embeddings import HuggingFaceEmbeddings\n",
    "from langchain.vectorstores import Chroma\n",
    "from langchain.document_loaders import (\n",
    "    TextLoader,\n",
    "    PyPDFLoader,\n",
    "    UnstructuredPDFLoader,\n",
    "    UnstructuredWordDocumentLoader\n",
    ")\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain.chains import RetrievalQA\n",
    "from langchain_community.llms import Ollama\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "58ae65a5-06e6-4b5a-8ef7-9d71aef3f15b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 1: Load Documents (.txt, .pdf, .docx)\n",
    "doc_dir = \"marxtexts\"\n",
    "texts = []\n",
    "for filename in os.listdir(doc_dir):\n",
    "    filepath = os.path.join(doc_dir, filename)\n",
    "\n",
    "    if filename.endswith(\".txt\"):\n",
    "        loader = TextLoader(filepath, encoding='utf-8')\n",
    "        texts.extend(loader.load())\n",
    "\n",
    "    elif filename.endswith(\".pdf\"):\n",
    "        try:\n",
    "            loader = PyPDFLoader(filepath)\n",
    "            texts.extend(loader.load())\n",
    "        except Exception:\n",
    "            loader = UnstructuredPDFLoader(filepath)\n",
    "            texts.extend(loader.load())\n",
    "\n",
    "    elif filename.endswith(\".docx\"):\n",
    "        loader = UnstructuredWordDocumentLoader(filepath)\n",
    "        texts.extend(loader.load())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "351474b5-8f0a-42f6-a939-674fb663f3a2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ebosjoy\\AppData\\Local\\Temp\\ipykernel_24748\\1934441728.py:5: LangChainDeprecationWarning: The class `HuggingFaceEmbeddings` was deprecated in LangChain 0.2.2 and will be removed in 1.0. An updated version of the class exists in the :class:`~langchain-huggingface package and should be used instead. To use it run `pip install -U :class:`~langchain-huggingface` and import as `from :class:`~langchain_huggingface import HuggingFaceEmbeddings``.\n",
      "  embedding_model = HuggingFaceEmbeddings(model_name=\"all-MiniLM-L6-v2\")\n",
      "C:\\Users\\ebosjoy\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sentence_transformers\\cross_encoder\\CrossEncoder.py:11: TqdmExperimentalWarning: Using `tqdm.autonotebook.tqdm` in notebook mode. Use `tqdm.tqdm` instead to force console mode (e.g. in jupyter console)\n",
      "  from tqdm.autonotebook import tqdm, trange\n"
     ]
    }
   ],
   "source": [
    "# Step 2: Split & Embed\n",
    "splitter = RecursiveCharacterTextSplitter(chunk_size=500, chunk_overlap=50)\n",
    "chunks = splitter.split_documents(texts)\n",
    "\n",
    "embedding_model = HuggingFaceEmbeddings(model_name=\"all-MiniLM-L6-v2\")\n",
    "vectorstore = Chroma.from_documents(chunks, embedding=embedding_model, persist_directory=\"marx_index\")\n",
    "vectorstore.persist()\n",
    "retriever = vectorstore.as_retriever()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7974e121-0623-4fc0-b66f-e75c7a0c1386",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 3: Load TinyLlama using Ollama\n",
    "llm = Ollama(model=\"tinyllama\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b6d8452-5bd6-4405-97da-7fbe3b35d582",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 4: Create QA Chain\n",
    "qa_chain = RetrievalQA.from_chain_type(llm=llm, retriever=retriever, chain_type=\"stuff\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5dad086-eaae-46ab-a7ca-bb667760521d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 5: Ask MarxBot\n",
    "while True:\n",
    "    query = input(\"\\nAsk MarxBot: \")\n",
    "    if query.lower() in [\"exit\", \"quit\"]:\n",
    "        break\n",
    "    result = qa_chain.run(query)\n",
    "    print(\"\\n\", result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79ffff09-9015-4960-8cd6-4f1ee9ae15c5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d32052cd-9f25-4f04-8ba5-319097387dd1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04ece77a-60d0-431a-a3b4-4ca61627e421",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
